{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from gflower.config.flow_matching import FlowMatchingEvaluationConfig\n",
    "from gflower.datasets.sequence import SequenceDataset\n",
    "from gflower.models_flow.flow_policy import FlowPolicy\n",
    "from gflower.models_flow.transformer import TransformerFlow\n",
    "from gflower.models_value.transformer import Transformer as ValueTransformer\n",
    "import torch\n",
    "import os\n",
    "import tqdm\n",
    "from gflower.config.flow_matching import TransformerConfig\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# get dataset only for its normalizer\n",
    "ENV_NAME = \"hopper-medium-expert-v2\"\n",
    "STATE_DIM = 11\n",
    "ACTION_DIM = 3\n",
    "HORIZON = 20\n",
    "GUIDE_SCALE = 0.05 # NOTE: when this is small, MC is more accurate. When it is increased, MC distribution saturates at some point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = SequenceDataset(\n",
    "    env=ENV_NAME,\n",
    "    horizon=20,\n",
    "    normalizer=\"GaussianNormalizer\",\n",
    "    preprocess_fns=[],\n",
    "    max_path_length=100000,\n",
    "    max_n_episodes=100000,\n",
    "    termination_penalty=0,\n",
    "    seed=0,\n",
    ")\n",
    "\n",
    "def prepare_evaluation(cfg: FlowMatchingEvaluationConfig):\n",
    "    # get policy\n",
    "\n",
    "    normalizer = dataset.normalizer\n",
    "\n",
    "    flow_transformer = TransformerFlow(\n",
    "        seq_len=cfg.horizon,\n",
    "        in_channels=cfg.state_dim + cfg.action_dim,\n",
    "        out_channels=cfg.state_dim + cfg.action_dim,\n",
    "        hidden_size=cfg.transformer_config.hidden_size,\n",
    "        depth=cfg.transformer_config.depth,\n",
    "        num_heads=cfg.transformer_config.num_heads,\n",
    "        mlp_ratio=cfg.transformer_config.mlp_ratio,\n",
    "        x_emb_proj=cfg.transformer_config.x_emb_proj,\n",
    "        x_emb_proj_conv_k=cfg.transformer_config.x_emb_proj_conv_k,\n",
    "    ).to(cfg.device)\n",
    "    flow_transformer.load_state_dict(torch.load(os.path.join(\n",
    "        cfg.log_folder, cfg.env, 'flow', cfg.flow_exp_name, f'model_ema_{cfg.flow_cp}.pth'\n",
    "    )))\n",
    "\n",
    "    # get value model\n",
    "    if cfg.guidance_method not in ['no']:\n",
    "        value_model = ValueTransformer(\n",
    "            input_dim=cfg.state_dim + cfg.action_dim,\n",
    "            output_dim=1,\n",
    "            model_dim=cfg.value_transformer_config.model_dim,\n",
    "            num_heads=cfg.value_transformer_config.num_heads,\n",
    "            num_layers=cfg.value_transformer_config.num_layers,\n",
    "            dropout=cfg.value_transformer_config.dropout,\n",
    "        ).to(cfg.device)\n",
    "        value_model.load_state_dict(torch.load(os.path.join(\n",
    "            cfg.log_folder, cfg.env, 'value', cfg.value_exp_name, f'model_{cfg.value_cp}.pth'\n",
    "        )))\n",
    "    else:\n",
    "        value_model = None\n",
    "\n",
    "    # get learned guidance model\n",
    "    if cfg.guidance_method == 'guidance_matching':\n",
    "        guide_model = TransformerFlow(\n",
    "            seq_len=cfg.horizon,\n",
    "            in_channels=cfg.state_dim + cfg.action_dim,\n",
    "            out_channels=(cfg.state_dim + cfg.action_dim) if cfg.guide_matching_type != 'grad_z' else 1,\n",
    "            hidden_size=cfg.guide_model_transformer_config.hidden_size,\n",
    "            depth=cfg.guide_model_transformer_config.depth,\n",
    "            num_heads=cfg.guide_model_transformer_config.num_heads,\n",
    "            mlp_ratio=cfg.guide_model_transformer_config.mlp_ratio,\n",
    "            x_emb_proj=cfg.guide_model_transformer_config.x_emb_proj,\n",
    "            x_emb_proj_conv_k=cfg.guide_model_transformer_config.x_emb_proj_conv_k,\n",
    "        ).to(cfg.device)\n",
    "        if cfg.guide_matching_type != 'grad_z':\n",
    "            guide_model.load_state_dict(torch.load(os.path.join(\n",
    "                cfg.log_folder, cfg.env, 'guidance', cfg.guide_model_exp_name, f'model_{cfg.guide_matching_type}_{cfg.guide_model_cp}.pth'\n",
    "            )))\n",
    "        else:\n",
    "            guide_model.load_state_dict(torch.load(os.path.join(\n",
    "                cfg.log_folder, cfg.env, 'guidance', cfg.guide_model_exp_name, f'model_z_{cfg.guide_model_cp}.pth'\n",
    "            )))\n",
    "    else:\n",
    "        guide_model = None\n",
    "    \n",
    "    flow_policy = FlowPolicy(\n",
    "        flow_model=flow_transformer,\n",
    "        value_model=value_model,\n",
    "        guide_model=guide_model,\n",
    "        normalizer=normalizer,\n",
    "        action_dim=cfg.action_dim,\n",
    "        state_dim=cfg.state_dim,\n",
    "        horizon=cfg.horizon,\n",
    "        cfg=cfg\n",
    "    )\n",
    "    return dataset.env, flow_policy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unconditioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from run.utils import deterministic\n",
    "\n",
    "\n",
    "deterministic(1)\n",
    "cfg = FlowMatchingEvaluationConfig(\n",
    "    device='cuda:0',\n",
    "    seed=0,\n",
    "    random_repeat=5,\n",
    "    exp_name=\"ablation_study\",\n",
    "    log_folder=\"../logs\",\n",
    "    env=ENV_NAME,\n",
    "    state_dim=STATE_DIM,\n",
    "    action_dim=ACTION_DIM,\n",
    "    horizon=HORIZON,\n",
    "    flow_exp_name=\"H20_1e6steps\",\n",
    "    flow_cp=19,\n",
    "    flow_matching_type=\"cfm\",\n",
    "    value_exp_name=\"H20_inf\",\n",
    "    value_cp=2,\n",
    "    ode_t_steps=30,\n",
    "    guidance_method=\"guidance_matching\",\n",
    "    guide_matching_type=\"grad_z\",\n",
    "    guide_scale=0,\n",
    "    guide_model_exp_name=f\"H20_scale_1.0_v3\",\n",
    "    guide_model_cp=2,\n",
    "    guide_inference_scale=0,\n",
    "    guide_model_transformer_config=TransformerConfig(\n",
    "        depth=4,\n",
    "        num_heads=4,\n",
    "        hidden_size=64\n",
    "    )\n",
    ")\n",
    "\n",
    "env, policy = prepare_evaluation(cfg)\n",
    "# simulate 1 step\n",
    "observation = env.reset()\n",
    "state = env.state_vector().copy()\n",
    "conditions = {0: observation}\n",
    "action, samples = policy(conditions, batch_size=2048) # this policy is \"replan-1\" in CL_DiffPhyCon\n",
    "\n",
    "unconditioned = samples.values[:, -1, 0].detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\nabla_{x_t} \\log Z_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg = FlowMatchingEvaluationConfig(\n",
    "    device='cuda:0',\n",
    "    seed=0,\n",
    "    random_repeat=5,\n",
    "    exp_name=\"ablation_study\",\n",
    "    log_folder=\"../logs\",\n",
    "    env=ENV_NAME,\n",
    "    state_dim=STATE_DIM,\n",
    "    action_dim=ACTION_DIM,\n",
    "    horizon=HORIZON,\n",
    "    flow_exp_name=\"H20_1e6steps\",\n",
    "    flow_cp=19,\n",
    "    flow_matching_type=\"cfm\",\n",
    "    value_exp_name=\"H20_inf\",\n",
    "    value_cp=2,\n",
    "    ode_t_steps=30,\n",
    "    guidance_method=\"guidance_matching\",\n",
    "    guide_matching_type=\"grad_z\",\n",
    "    guide_scale=1.0,\n",
    "    guide_model_exp_name=f\"H20_scale_10.0_v3\",\n",
    "    guide_model_cp=2,\n",
    "    guide_inference_scale=100.0,\n",
    "    guide_model_transformer_config=TransformerConfig(\n",
    "        depth=4,\n",
    "        num_heads=4,\n",
    "        hidden_size=64\n",
    "    )\n",
    ")\n",
    "env, policy = prepare_evaluation(cfg)\n",
    "# simulate 1 step\n",
    "observation = env.reset()\n",
    "state = env.state_vector().copy()\n",
    "conditions = {0: observation}\n",
    "action, samples = policy(conditions, batch_size=1024) # this policy is \"replan-1\" in CL_DiffPhyCon\n",
    "\n",
    "values_logz = samples.values[:, -1, 0].detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grad xt x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg = FlowMatchingEvaluationConfig(\n",
    "    device='cuda:0',\n",
    "    seed=0,\n",
    "    random_repeat=5,\n",
    "    exp_name=\"ablation_study\",\n",
    "    log_folder=\"../logs\",\n",
    "    env=ENV_NAME,\n",
    "    state_dim=STATE_DIM,\n",
    "    action_dim=ACTION_DIM,\n",
    "    horizon=HORIZON,\n",
    "    flow_exp_name=\"H20_1e6steps\",\n",
    "    flow_cp=19,\n",
    "    flow_matching_type=\"cfm\",\n",
    "    value_exp_name=\"H20_inf\",\n",
    "    value_cp=2,\n",
    "    ode_t_steps=30,\n",
    "    guidance_method=\"gradient\",\n",
    "    grad_compute_at=\"x_1\",\n",
    "    grad_wrt=\"x_t\",\n",
    "    grad_schedule=\"cosine_decay\",\n",
    "    grad_scale=2,\n",
    ")\n",
    "env, policy = prepare_evaluation(cfg)\n",
    "# simulate 1 step\n",
    "observation = env.reset()\n",
    "state = env.state_vector().copy()\n",
    "conditions = {0: observation}\n",
    "action, samples = policy(conditions, batch_size=1024) # this policy is \"replan-1\" in CL_DiffPhyCon\n",
    "\n",
    "grad_xt_x1 = samples.values[:, -1, 0].detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grad x1 x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg = FlowMatchingEvaluationConfig(\n",
    "    device='cuda:0',\n",
    "    seed=0,\n",
    "    random_repeat=5,\n",
    "    exp_name=\"ablation_study\",\n",
    "    log_folder=\"../logs\",\n",
    "    env=ENV_NAME,\n",
    "    state_dim=STATE_DIM,\n",
    "    action_dim=ACTION_DIM,\n",
    "    horizon=HORIZON,\n",
    "    flow_exp_name=\"H20_1e6steps\",\n",
    "    flow_cp=19,\n",
    "    flow_matching_type=\"cfm\",\n",
    "    value_exp_name=\"H20_inf\",\n",
    "    value_cp=2,\n",
    "    ode_t_steps=30,\n",
    "    guidance_method=\"gradient\",\n",
    "    grad_compute_at=\"x_1\",\n",
    "    grad_wrt=\"x_1\",\n",
    "    grad_schedule=\"cosine_decay\",\n",
    "    grad_scale=1,\n",
    ")\n",
    "env, policy = prepare_evaluation(cfg)\n",
    "# simulate 1 step\n",
    "observation = env.reset()\n",
    "state = env.state_vector().copy()\n",
    "conditions = {0: observation}\n",
    "action, samples = policy(conditions, batch_size=1024) # this policy is \"replan-1\" in CL_DiffPhyCon\n",
    "\n",
    "grad_x1_x1 = samples.values[:, -1, 0].detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda clear cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deterministic(0)\n",
    "mc_all = np.array([])\n",
    "for _ in tqdm.tqdm(range(256 // 64)):\n",
    "    cfg = FlowMatchingEvaluationConfig(\n",
    "        device='cuda:0',\n",
    "        seed=0,\n",
    "        random_repeat=5,\n",
    "        exp_name=\"ablation_study\",\n",
    "        log_folder=\"../logs\",\n",
    "        env=ENV_NAME,\n",
    "        state_dim=STATE_DIM,\n",
    "        action_dim=ACTION_DIM,\n",
    "        horizon=HORIZON,\n",
    "        flow_exp_name=\"H20_1e6steps\",\n",
    "        flow_cp=19,\n",
    "        flow_matching_type=\"cfm\",\n",
    "        value_exp_name=\"H20_inf\",\n",
    "        value_cp=2,\n",
    "        ode_t_steps=30,\n",
    "        guidance_method=\"mc\",\n",
    "        mc_batch_size=256,\n",
    "        mc_scale=GUIDE_SCALE,\n",
    "        mc_ep=1e-2,\n",
    "        mc_ss=1,\n",
    "        mc_self_normalize=False, # we open this in actual experiment for more stable performance, but False is exat MC guidance\n",
    "    )\n",
    "    env, policy = prepare_evaluation(cfg)\n",
    "    # simulate 1 step\n",
    "    observation = env.reset()\n",
    "    state = env.state_vector().copy()\n",
    "    conditions = {0: observation}\n",
    "    action, samples = policy(conditions, batch_size=64) # this policy is \"replan-1\" in CL_DiffPhyCon\n",
    "\n",
    "    mc = samples.values\n",
    "    mc_all = np.append(mc_all, mc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guidance Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg = FlowMatchingEvaluationConfig(\n",
    "    device='cuda:0',\n",
    "    seed=0,\n",
    "    random_repeat=5,\n",
    "    exp_name=\"ablation_study\",\n",
    "    log_folder=\"../logs\",\n",
    "    env=ENV_NAME,\n",
    "    state_dim=STATE_DIM,\n",
    "    action_dim=ACTION_DIM,\n",
    "    horizon=HORIZON,\n",
    "    flow_exp_name=\"H20_1e6steps\",\n",
    "    flow_cp=19,\n",
    "    flow_matching_type=\"cfm\",\n",
    "    value_exp_name=\"H20_inf\",\n",
    "    value_cp=2,\n",
    "    ode_t_steps=30,\n",
    "    guidance_method=\"guidance_matching\",\n",
    "    guide_matching_type=\"direct\",\n",
    "    guide_scale=7.0,\n",
    "    guide_model_exp_name=f\"H20_scale_10.0_g_direct_v5\",\n",
    "    guide_model_cp=2,\n",
    "    guide_inference_scale=10.0,\n",
    "    guide_model_transformer_config=TransformerConfig(\n",
    "        depth=2,\n",
    "        num_heads=2,\n",
    "        hidden_size=64\n",
    "    )\n",
    ")\n",
    "env, policy = prepare_evaluation(cfg)\n",
    "# simulate 1 step\n",
    "observation = env.reset()\n",
    "state = env.state_vector().copy()\n",
    "conditions = {0: observation}\n",
    "action, samples = policy(conditions, batch_size=1024) # this policy is \"replan-1\" in CL_DiffPhyCon\n",
    "\n",
    "gm = samples.values[:, -1, 0].detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg = FlowMatchingEvaluationConfig(\n",
    "    device='cuda:0',\n",
    "    seed=0,\n",
    "    random_repeat=5,\n",
    "    exp_name=\"ablation_study\",\n",
    "    log_folder=\"../logs\",\n",
    "    env=ENV_NAME,\n",
    "    state_dim=STATE_DIM,\n",
    "    action_dim=ACTION_DIM,\n",
    "    horizon=HORIZON,\n",
    "    flow_exp_name=\"H20_1e6steps\",\n",
    "    flow_cp=19,\n",
    "    flow_matching_type=\"cfm\",\n",
    "    value_exp_name=\"H20_inf\",\n",
    "    value_cp=2,\n",
    "    ode_t_steps=30,\n",
    "    guidance_method=\"guidance_matching\",\n",
    "    guide_matching_type=\"use_learned_v\",\n",
    "    guide_scale=1.0,\n",
    "    guide_model_exp_name=f\"H20_scale_1.0_g_use_learned_v_v5\",\n",
    "    guide_model_cp=2,\n",
    "    guide_inference_scale=10.0,\n",
    "    guide_model_transformer_config=TransformerConfig(\n",
    "        depth=2,\n",
    "        num_heads=2,\n",
    "        hidden_size=64\n",
    "    )\n",
    ")\n",
    "env, policy = prepare_evaluation(cfg)\n",
    "# simulate 1 step\n",
    "observation = env.reset()\n",
    "state = env.state_vector().copy()\n",
    "conditions = {0: observation}\n",
    "action, samples = policy(conditions, batch_size=1024) # this policy is \"replan-1\" in CL_DiffPhyCon\n",
    "\n",
    "vgm = samples.values[:, -1, 0].detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg = FlowMatchingEvaluationConfig(\n",
    "    device='cuda:0',\n",
    "    seed=0,\n",
    "    random_repeat=5,\n",
    "    exp_name=\"ablation_study\",\n",
    "    log_folder=\"../logs\",\n",
    "    env=ENV_NAME,\n",
    "    state_dim=STATE_DIM,\n",
    "    action_dim=ACTION_DIM,\n",
    "    horizon=HORIZON,\n",
    "    flow_exp_name=\"H20_1e6steps\",\n",
    "    flow_cp=19,\n",
    "    flow_matching_type=\"cfm\",\n",
    "    value_exp_name=\"H20_inf\",\n",
    "    value_cp=2,\n",
    "    ode_t_steps=30,\n",
    "    guidance_method=\"guidance_matching\",\n",
    "    guide_matching_type=\"rw_use_learned_z\",\n",
    "    guide_scale=1.0,\n",
    "    guide_model_exp_name=f\"H20_scale_1.0_g_rw_use_learned_z_v5\",\n",
    "    guide_model_cp=2,\n",
    "    guide_inference_scale=1.0,\n",
    "    guide_model_transformer_config=TransformerConfig(\n",
    "        depth=2,\n",
    "        num_heads=2,\n",
    "        hidden_size=64\n",
    "    )\n",
    ")\n",
    "env, policy = prepare_evaluation(cfg)\n",
    "# simulate 1 step\n",
    "observation = env.reset()\n",
    "state = env.state_vector().copy()\n",
    "conditions = {0: observation}\n",
    "action, samples = policy(conditions, batch_size=1024) # this policy is \"replan-1\" in CL_DiffPhyCon\n",
    "\n",
    "rgm = samples.values[:, -1, 0].detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MRGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg = FlowMatchingEvaluationConfig(\n",
    "    device='cuda:0',\n",
    "    seed=0,\n",
    "    random_repeat=5,\n",
    "    exp_name=\"ablation_study\",\n",
    "    log_folder=\"../logs\",\n",
    "    env=ENV_NAME,\n",
    "    state_dim=STATE_DIM,\n",
    "    action_dim=ACTION_DIM,\n",
    "    horizon=HORIZON,\n",
    "    flow_exp_name=\"H20_1e6steps\",\n",
    "    flow_cp=19,\n",
    "    flow_matching_type=\"cfm\",\n",
    "    value_exp_name=\"H20_inf\",\n",
    "    value_cp=2,\n",
    "    ode_t_steps=30,\n",
    "    guidance_method=\"guidance_matching\",\n",
    "    guide_matching_type=\"rw\",\n",
    "    guide_scale=1.0,\n",
    "    guide_model_exp_name=f\"H20_scale_1.0_g_rw_v5\",\n",
    "    guide_model_cp=2,\n",
    "    guide_inference_scale=1.0,\n",
    "    guide_model_transformer_config=TransformerConfig(\n",
    "        depth=2,\n",
    "        num_heads=2,\n",
    "        hidden_size=64\n",
    "    )\n",
    ")\n",
    "env, policy = prepare_evaluation(cfg)\n",
    "# simulate 1 step\n",
    "observation = env.reset()\n",
    "state = env.state_vector().copy()\n",
    "conditions = {0: observation}\n",
    "action, samples = policy(conditions, batch_size=1024) # this policy is \"replan-1\" in CL_DiffPhyCon\n",
    "\n",
    "mrgm = samples.values[:, -1, 0].detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples.values.shape)\n",
    "\n",
    "nbins = 20\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "# Plot histogram value using curves instead of bars\n",
    "unconditioned_height = ax.hist(unconditioned, bins=nbins, alpha=0.5, label='$p(R)$', density=True)\n",
    "\n",
    "# reweight unconditioned height with exp values\n",
    "values = np.linspace(unconditioned.min(), unconditioned.max(), nbins)\n",
    "unconditioned_height = unconditioned_height[0] * np.exp(GUIDE_SCALE * values)\n",
    "unconditioned_height = unconditioned_height / unconditioned_height.sum() / (values[1] - values[0])\n",
    "ax.plot(values, unconditioned_height, label='$\\\\frac{1}{Z}p(R)e^{R(x_1)}$', ls='--', lw=4, color='grey', zorder=100)\n",
    "\n",
    "ax.hist(mc_all, bins=nbins, alpha=0.5, label='$g^{MC}$', density=True, zorder=10)\n",
    "# ax.hist(values_logz, bins=nbins, alpha=0.5, label='Learned $\\log Z_t$', density=True)\n",
    "ax.hist(grad_xt_x1, bins=nbins, alpha=0.5, label='$g^{cov-G}$', density=True)\n",
    "ax.hist(grad_x1_x1, bins=nbins, alpha=0.5, label='$g^{cov-A}$', density=True)\n",
    "# ax.hist(gm, bins=nbins, alpha=0.5, label='GM', density=True, zorder=10)\n",
    "# ax.hist(vgm, bins=nbins, alpha=0.5, label='VGM', density=True, zorder=10)\n",
    "# ax.hist(rgm, bins=nbins, alpha=0.5, label='RGM', density=True, zorder=10)\n",
    "# ax.hist(mrgm, bins=nbins, alpha=0.5, label='MRGM', density=True, zorder=10)\n",
    "\n",
    "ax.legend(bbox_to_anchor=(1.05, 0.2, 0.33, 0.2), loc=\"lower left\",\n",
    "          mode=\"expand\", borderaxespad=0, ncol=1)\n",
    "\n",
    "ax.set_xlabel('Estimated $R$')\n",
    "ax.set_ylabel('Probability Density of \\n Generated Samples')\n",
    "# ax.set_title('Distribution of $R$')\n",
    "\n",
    "fig.set_size_inches(5, 3.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(f'../images/ablation_generated_return_{ENV_NAME}_scale_{GUIDE_SCALE}_small.pdf', bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples.values.shape)\n",
    "\n",
    "nbins = 20\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "# Plot histogram value using curves instead of bars\n",
    "unconditioned_height = ax.hist(unconditioned, bins=nbins, alpha=0.5, label='$p(R)$ (w/o guidance)', density=True)\n",
    "\n",
    "# reweight unconditioned height with exp values\n",
    "values = np.linspace(unconditioned.min(), unconditioned.max(), nbins)\n",
    "unconditioned_height = unconditioned_height[0] * np.exp(GUIDE_SCALE * values)\n",
    "unconditioned_height = unconditioned_height / unconditioned_height.sum() / (values[1] - values[0])\n",
    "ax.plot(values, unconditioned_height, label='$\\\\frac{1}{Z}p(R)e^{R(x_1)}$', ls='--', lw=4, color='grey', zorder=100)\n",
    "\n",
    "ax.hist(mc_all, bins=nbins, alpha=0.5, label='$g^{MC}$', density=True, zorder=10)\n",
    "# ax.hist(values_logz, bins=nbins, alpha=0.5, label='Learned $\\log Z_t$', density=True)\n",
    "ax.hist(grad_xt_x1, bins=nbins, alpha=0.5, label='$g^{cov-G}$', density=True)\n",
    "ax.hist(grad_x1_x1, bins=nbins, alpha=0.5, label='$g^{cov-A}$', density=True)\n",
    "# ax.hist(gm, bins=nbins, alpha=0.5, label='GM', density=True, zorder=10)\n",
    "# ax.hist(vgm, bins=nbins, alpha=0.5, label='VGM', density=True, zorder=10)\n",
    "# ax.hist(rgm, bins=nbins, alpha=0.5, label='RGM', density=True, zorder=10)\n",
    "# ax.hist(mrgm, bins=nbins, alpha=0.5, label='MRGM', density=True, zorder=10)\n",
    "\n",
    "ax.legend(bbox_to_anchor=(0, 1.15, 1.0, 0.2), loc=\"lower left\",\n",
    "          mode=\"expand\", borderaxespad=0, ncol=3)\n",
    "\n",
    "ax.set_xlabel('Estimated $R$')\n",
    "ax.set_ylabel('Probability Density of \\n Generated Samples')\n",
    "ax.set_title('Distribution of $R$')\n",
    "\n",
    "fig.set_size_inches(5, 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(f'../images/ablation_generated_return_{ENV_NAME}_scale_{GUIDE_SCALE}.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
