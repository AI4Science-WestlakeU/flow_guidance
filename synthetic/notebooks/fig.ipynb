{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## {Gaussian, Uniform} to 8-Gaussian, guidance with Learned, MC, CEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from functools import partial\n",
    "from typing import List, Tuple\n",
    "from guided_flow.backbone.mlp import MLP\n",
    "from guided_flow.backbone.wrapper import ExpEnergyMLPWrapper, GuidedMLPWrapper, MLPWrapper\n",
    "from guided_flow.config.sampling import GuideFnConfig\n",
    "from guided_flow.distributions.base import BaseDistribution, get_distribution\n",
    "from guided_flow.distributions.gaussian import GaussianDistribution\n",
    "from guided_flow.flow.optimal_transport import OTPlanSampler\n",
    "from guided_flow.guidance.gradient_guidance import wrap_grad_fn\n",
    "from guided_flow.utils.misc import deterministic\n",
    "from guided_flow.utils.metrics import compute_w2 as w2\n",
    "import torch\n",
    "from torchdyn.core import NeuralODE\n",
    "import numpy as np\n",
    "from torch.distributions import Normal, Independent\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from guided_flow.config.sampling import ODEConfig\n",
    "\n",
    "\n",
    "from guided_flow.utils.kl_divergence import compute_kl_divergence\n",
    "MLP_WIDTH = 256\n",
    "TRAINING_B = 256 # OT CFM training batch size\n",
    "\n",
    "\n",
    "def sample_x1_frompeJ(x1_sampler, x1_dist, device, B):\n",
    "    x1 = None\n",
    "    while x1 is None or x1.shape[0] < B:\n",
    "        x1_ = x1_sampler(B).to(device)\n",
    "        weights = torch.exp(-x1_dist.get_J(x1_))\n",
    "        acc_prob = weights / weights.max()\n",
    "        random_numbers = torch.rand(B, device=device)\n",
    "        x1_ = x1_[random_numbers < acc_prob]\n",
    "        if x1 is None:\n",
    "            x1 = x1_\n",
    "        else:\n",
    "            x1 = torch.cat([x1, x1_], 0)\n",
    "    x1 = x1[:B]\n",
    "    return x1\n",
    "\n",
    "\n",
    "def compute_w2(trajs, cfgs: List[GuideFnConfig]):\n",
    "    w2s = []\n",
    "    for traj, cfg in zip(trajs, cfgs):\n",
    "        x0_dist = get_distribution(cfg.dist_pair[0])\n",
    "        x1_dist = get_distribution(cfg.dist_pair[1])\n",
    "        \n",
    "        x1 = sample_x1_frompeJ(x1_dist.sample, x1_dist, cfg.ode_cfg.device, cfg.ode_cfg.batch_size)\n",
    "        w2s.append(w2(traj[-1], x1))\n",
    "    return w2s\n",
    "\n",
    "\n",
    "def get_mc_guide_fn(x0_dist: BaseDistribution, x1_dist: BaseDistribution, mc_cfg: GuideFnConfig, cfm: str):\n",
    "\n",
    "    def log_cfm_p_t1(x1, xt, t):\n",
    "        # xt = t x1 + (1 - t) x0 -> x0 = xt / (1 - t) - t / (1 - t) x1\n",
    "        x0 = xt / (1 - t + mc_cfg.ep) - (t + mc_cfg.ep) / (1 - t + mc_cfg.ep) * x1 # (B, 2)\n",
    "        p1t = x0_dist.prob(x0).clamp(1e-8) / (1 - t[0] + mc_cfg.ep) ** 2 # (B,)\n",
    "        log_p1t = p1t.log()\n",
    "        # print(log_p1t.mean())\n",
    "        return log_p1t\n",
    "        \n",
    "    def guide_fn(t, x, dx_dt, model, x0=None, x1=None, Jx1=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            t: Tensor, shape (b, 1)\n",
    "            x: Tensor, shape (b, dim)\n",
    "            dx_dt: Tensor, shape (b, dim)\n",
    "            model: MLP\n",
    "        \"\"\"\n",
    "        # estimate E (e^{-J} / Z - 1) * u\n",
    "        b = x.shape[0]\n",
    "        B = mc_cfg.mc_batch_size\n",
    "        x_ = x.repeat(B, 1) # (MC_B * b, 2)\n",
    "        t_ = t.repeat(B * b, 1) # (MC_B * b)\n",
    "        if cfm == 'cfm':\n",
    "            log_p_t1_x = log_cfm_p_t1(x1, x_, t_) # (MC_B * b) # TODO\n",
    "            log_p_t_x = log_p_t1_x.reshape(B, b, 1).logsumexp(0) - torch.log(torch.tensor(B, device=x.device)) # (MC_B, B, 1) -> (B, 1)\n",
    "            log_p_t1_x_times_J_ = (log_p_t1_x + torch.log(Jx1)).reshape(B, b, 1) # (MC_B * b) -> (MC_B, b, 1)            \n",
    "            logZ = torch.logsumexp(log_p_t1_x_times_J_, 0) - torch.log(torch.tensor(B, device=x.device)) - log_p_t_x # (b, 1)\n",
    "\n",
    "            Z = torch.exp(logZ)\n",
    "            u = (x1 - x_) / (1 - t_ + mc_cfg.ep) # (MC_B * b, dim)\n",
    "\n",
    "            g = (log_p_t1_x.reshape(B, b, 1) - log_p_t_x.unsqueeze(0)).exp() * (Jx1.reshape(B, b, 1) / (Z + 1e-8).unsqueeze(0) - 1) * u.reshape(B, b, 2) # (MC_B, b, dim)\n",
    "\n",
    "            return g.mean(0)\n",
    "\n",
    "    \n",
    "    x1 = x1_dist.sample(mc_cfg.mc_batch_size).to(mc_cfg.ode_cfg.device).unsqueeze(0).repeat(mc_cfg.ode_cfg.batch_size, 1, 1).permute(1, 0, 2).reshape(-1, 2)\n",
    "    Jx1 = torch.exp(-mc_cfg.scale * x1_dist.get_J(x1))\n",
    "    return partial(\n",
    "        guide_fn, \n",
    "        x1=x1, \n",
    "        Jx1=Jx1\n",
    "    )\n",
    "\n",
    "def get_guide_fn(dist: BaseDistribution, cfg: GuideFnConfig):\n",
    "    def guide_fn(t, x, dx_dt, model):\n",
    "\n",
    "        if cfg.guide_type == 'g_cov_A':\n",
    "            x1_pred = x + dx_dt * (1 - t)\n",
    "            J = dist.get_J(x1_pred)\n",
    "            try:\n",
    "                with torch.enable_grad():\n",
    "                    x1_pred = x1_pred.requires_grad_(True)\n",
    "                    J = dist.get_J(x1_pred)\n",
    "                    grad = -torch.autograd.grad(J.sum(), x1_pred, create_graph=True)[0]\n",
    "                    return grad\n",
    "            except Exception as e:\n",
    "                return torch.zeros_like(x)\n",
    "        \n",
    "        elif cfg.guide_type == 'g_cov_G':\n",
    "            with torch.enable_grad():\n",
    "                x = x.requires_grad_(True)\n",
    "                x1_pred = x + model(torch.cat([x, t.repeat(x.shape[0])[:, None]], 1)) * (1 - t)\n",
    "                J = dist.get_J(x1_pred)\n",
    "                try:\n",
    "                    grad = -torch.autograd.grad(J.sum(), x, create_graph=True)[0]\n",
    "                    return grad\n",
    "                except Exception as e:\n",
    "                    return torch.zeros_like(x)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown guide function: {cfg.guide_type}\")\n",
    "    # make scale and schedule\n",
    "    return wrap_grad_fn(cfg.guide_scale, cfg.guide_schedule, guide_fn)\n",
    "\n",
    "def get_sim_mc_guide_fn(x1_dist: BaseDistribution, cfg: GuideFnConfig):\n",
    "    def guide_fn(t, x, dx_dt, model):\n",
    "        \"\"\"\n",
    "        Implements guidance following Eq. 12\n",
    "        Args:\n",
    "            t: flow time. float\n",
    "            x: current sample x_t. Tensor, shape (b, dim)\n",
    "            dx_dt: current predicted VF. Tensor, shape (b, dim)\n",
    "            model: flow model. MLP\n",
    "        \"\"\"\n",
    "        x1_pred = x + dx_dt * (1 - t) # (B, 2)\n",
    "        std = cfg.sim_mc_std\n",
    "        \n",
    "        x1 = torch.randn_like(x1_pred.unsqueeze(0).repeat(cfg.sim_mc_n, 1, 1)) * std + x1_pred # (cfg.sim_mc_n, B, 2)\n",
    "        Jx1_ = torch.exp(-cfg.scale * x1_dist.get_J(x1.reshape(-1, 2))).reshape(cfg.sim_mc_n, -1) # (cfg.sim_mc_n, B)\n",
    "        v = (x1 - x) / (1 - t + cfg.ep)  # Conditional VF v_{t|z} in Eq. 12 (cfg.sim_mc_n, B, 2)\n",
    "        Z = Jx1_.mean(0) + 1e-8  # Z in Eq. 12 (B,)\n",
    "        g = (Jx1_ / Z - 1).unsqueeze(2) * v  # g in Eq. 12 (cfg.sim_mc_n, B, 2)\n",
    "        return g.mean(0)\n",
    "    return wrap_grad_fn(cfg.guide_scale, cfg.guide_schedule, guide_fn)\n",
    "\n",
    "def evaluate(x0_sampler, x1_sampler, model, guide_fn, cfg: ODEConfig):\n",
    "    node = NeuralODE(\n",
    "        GuidedMLPWrapper(\n",
    "            model, \n",
    "            guide_fn=guide_fn,\n",
    "            scheduler=lambda t: 1\n",
    "        ), \n",
    "        solver=\"euler\", sensitivity=\"adjoint\", atol=1e-4, rtol=1e-4\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        traj = node.trajectory(\n",
    "            x0_sampler(cfg.batch_size).to(cfg.device), \n",
    "            t_span=torch.linspace(0, cfg.t_end, cfg.num_steps)\n",
    "        )\n",
    "    \n",
    "    return traj\n",
    "\n",
    "\n",
    "def sample_and_compute_w2(guide_cfgs: List[GuideFnConfig]):\n",
    "    print(\"Monte Carlo batch size:\", guide_cfgs[0].mc_batch_size)\n",
    "\n",
    "    trajs = []\n",
    "\n",
    "    for cfg in guide_cfgs:\n",
    "\n",
    "        # Initialize samplers, model and guidance model\n",
    "        x0_dist = get_distribution(cfg.dist_pair[0])\n",
    "        x1_dist = get_distribution(cfg.dist_pair[1])\n",
    "\n",
    "        x0_sampler = x0_dist.sample\n",
    "        x1_sampler = x1_dist.sample\n",
    "\n",
    "        model = MLP(dim=2, w=MLP_WIDTH, time_varying=True).to(cfg.ode_cfg.device)\n",
    "        model.load_state_dict(torch.load(f'../logs/{cfg.dist_pair[0]}-{cfg.dist_pair[1]}/{cfg.cfm}_{cfg.dist_pair[0]}_{cfg.dist_pair[1]}/{cfg.cfm}_{cfg.dist_pair[0]}_{cfg.dist_pair[1]}.pth'))\n",
    "\n",
    "        if cfg.guide_type == 'mc':\n",
    "            # sample using flow model\n",
    "            traj = evaluate(x0_sampler, x1_sampler, model, get_mc_guide_fn(x0_dist, x1_dist, cfg, cfg.cfm), cfg.ode_cfg)\n",
    "            \n",
    "        elif cfg.guide_type == 'learned':\n",
    "            model_G = MLP(dim=2, out_dim=2, w=MLP_WIDTH, time_varying=True).to(cfg.ode_cfg.device)\n",
    "            model_G.load_state_dict(torch.load(f'../logs/{cfg.dist_pair[0]}-{cfg.dist_pair[1]}/{cfg.cfm}_{cfg.dist_pair[0]}_{cfg.dist_pair[1]}/guidance_matching_{cfg.gm_type}_scale_{cfg.scale}_{cfg.dist_pair[0]}_{cfg.dist_pair[1]}.pth'))\n",
    "            traj = evaluate(x0_sampler, x1_sampler, model, MLPWrapper(model_G, scheduler=lambda t: 1., clamp=0), cfg.ode_cfg)\n",
    "        \n",
    "        elif cfg.guide_type == 'ceg':\n",
    "            model_Z = MLP(dim=2, out_dim=1, w=MLP_WIDTH, time_varying=True, exp_final=False).to(cfg.ode_cfg.device)\n",
    "            model_Z.load_state_dict(torch.load(f'../logs/{cfg.dist_pair[0]}-{cfg.dist_pair[1]}/{cfg.cfm}_{cfg.dist_pair[0]}_{cfg.dist_pair[1]}/ceg_scale_{cfg.scale}_{cfg.dist_pair[0]}_{cfg.dist_pair[1]}.pth'))\n",
    "            \n",
    "            # 2D xy plane. make uniform grid\n",
    "            XX = torch.linspace(0, 1, 100)\n",
    "            YY = torch.linspace(0, 1, 100)\n",
    "            XX, YY = torch.meshgrid(XX, YY, indexing='ij')\n",
    "            xy = torch.stack([XX.flatten(), YY.flatten()], 1)\n",
    "            t = torch.zeros(10000, 1) + 0.9\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.imshow(model_Z(torch.cat([xy, t], 1).to(cfg.ode_cfg.device)).detach().cpu().numpy().reshape(100, 100))\n",
    "            \n",
    "            traj = evaluate(x0_sampler, x1_sampler, model, ExpEnergyMLPWrapper(model_Z, scheduler=lambda t: 1, clamp=1), cfg.ode_cfg)\n",
    "        \n",
    "        elif cfg.guide_type in ['g_cov_A', 'g_cov_G']:\n",
    "            traj = evaluate(x0_sampler, x1_sampler, model, get_guide_fn(x1_dist, cfg), cfg.ode_cfg)\n",
    "\n",
    "        elif cfg.guide_type == 'g_sim_MC':\n",
    "            traj = evaluate(x0_sampler, x1_sampler, model, get_sim_mc_guide_fn(x1_dist, cfg), cfg.ode_cfg)\n",
    "        trajs.append(traj)\n",
    "    return trajs, None\n",
    "\n",
    "deterministic(0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_cfgs_mc_cfm = [\n",
    "    GuideFnConfig(dist_pair=('circle', 's_curve'), mc_batch_size=10240, ep=5e-2, scale=1, ode_cfg=ODEConfig(t_end=0.95, num_steps=100)), \n",
    "    GuideFnConfig(dist_pair=('uniform', '8gaussian'), mc_batch_size=10240, ep=1e-3, ode_cfg=ODEConfig(t_end=1, num_steps=100)), \n",
    "    GuideFnConfig(dist_pair=('8gaussian', 'moon'), mc_batch_size=1024, ep=1e-2, scale=1, ode_cfg=ODEConfig(t_end=1.0, num_steps=100)), \n",
    "]\n",
    "\n",
    "deterministic(0)\n",
    "trajs_mc_cfm, w2s_mc_cfm = sample_and_compute_w2(guide_cfgs_mc_cfm)\n",
    "compute_w2(trajs_mc_cfm, guide_cfgs_mc_cfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_cfgs_gm_cfm = [\n",
    "    GuideFnConfig(dist_pair=('circle', 's_curve'), guide_type='learned', ep=1e-2, gm_type='g3', ode_cfg=ODEConfig(t_end=1.0, num_steps=100)), \n",
    "    GuideFnConfig(dist_pair=('uniform', '8gaussian'), guide_type='learned', ep=1e-3, gm_type='g3', ode_cfg=ODEConfig(t_end=1.0, num_steps=100)), \n",
    "    GuideFnConfig(dist_pair=('8gaussian', 'moon'), guide_type='learned', ep=1e-2, gm_type='g3', ode_cfg=ODEConfig(t_end=1.0, num_steps=100)), \n",
    "]\n",
    "\n",
    "trajs_gm_cfm, w2s_gm_cfm = sample_and_compute_w2(guide_cfgs_gm_cfm)\n",
    "compute_w2(trajs_gm_cfm, guide_cfgs_gm_cfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_cfgs_ceg_cfm = [\n",
    "    GuideFnConfig(dist_pair=('circle', 's_curve'), guide_type='ceg', ep=1e-2, ode_cfg=ODEConfig(t_end=0.95, num_steps=100)), \n",
    "    GuideFnConfig(dist_pair=('uniform', '8gaussian'), guide_type='ceg', ep=1e-3, ode_cfg=ODEConfig(t_end=0.95, num_steps=100)), \n",
    "    GuideFnConfig(dist_pair=('8gaussian', 'moon'), guide_type='ceg', ep=1e-2, ode_cfg=ODEConfig(t_end=0.95, num_steps=100)), \n",
    "]\n",
    "\n",
    "trajs_ceg_cfm, w2s_ceg_cfm = sample_and_compute_w2(guide_cfgs_ceg_cfm)\n",
    "compute_w2(trajs_ceg_cfm, guide_cfgs_ceg_cfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_cfgs_g_cov_a_cfm = [\n",
    "    GuideFnConfig(dist_pair=('circle', 's_curve'), guide_type='g_cov_A', guide_scale=0.2, guide_schedule='exp_decay', ep=1e-2, ode_cfg=ODEConfig(t_end=1.0, num_steps=100)), \n",
    "    GuideFnConfig(dist_pair=('uniform', '8gaussian'), guide_type='g_cov_A', guide_scale=1.0, guide_schedule='linear_decay', ep=1e-3, ode_cfg=ODEConfig(t_end=1.0, num_steps=100)), \n",
    "    GuideFnConfig(dist_pair=('8gaussian', 'moon'), guide_type='g_cov_A', guide_scale=2.0, guide_schedule='linear_decay', ep=1e-2, ode_cfg=ODEConfig(t_end=1.0, num_steps=100)), \n",
    "]\n",
    "\n",
    "trajs_g_cov_a_cfm, w2s_g_cov_a_cfm = sample_and_compute_w2(guide_cfgs_g_cov_a_cfm)\n",
    "compute_w2(trajs_g_cov_a_cfm, guide_cfgs_g_cov_a_cfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_cfgs_g_cov_g_cfm = [\n",
    "    GuideFnConfig(dist_pair=('circle', 's_curve'), guide_type='g_cov_G', guide_scale=0.2, guide_schedule='exp_decay', ep=1e-2, ode_cfg=ODEConfig(t_end=1.0, num_steps=100)), \n",
    "    GuideFnConfig(dist_pair=('uniform', '8gaussian'), guide_type='g_cov_G', guide_scale=1.0, guide_schedule='linear_decay', ep=1e-3, ode_cfg=ODEConfig(t_end=1.0, num_steps=100)), \n",
    "    GuideFnConfig(dist_pair=('8gaussian', 'moon'), guide_type='g_cov_G', guide_scale=2.0, guide_schedule='linear_decay', ep=1e-2, ode_cfg=ODEConfig(t_end=1.0, num_steps=100)), \n",
    "]\n",
    "\n",
    "trajs_g_cov_g_cfm, w2s_g_cov_g_cfm = sample_and_compute_w2(guide_cfgs_g_cov_g_cfm)\n",
    "compute_w2(trajs_g_cov_g_cfm, guide_cfgs_g_cov_g_cfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_cfgs_g_sim_MC_cfm = [\n",
    "    GuideFnConfig(dist_pair=('circle', 's_curve'), guide_type='g_sim_MC', sim_mc_std=1, sim_mc_n=100, ep=1e-2, guide_scale=2.0, guide_schedule='linear_decay', ode_cfg=ODEConfig(t_end=1.0, num_steps=100)), \n",
    "    GuideFnConfig(dist_pair=('uniform', '8gaussian'), guide_type='g_sim_MC', sim_mc_std=1, sim_mc_n=100, ep=1e-2, guide_scale=1, guide_schedule='linear_decay', ode_cfg=ODEConfig(t_end=1.0, num_steps=100)), \n",
    "    GuideFnConfig(dist_pair=('8gaussian', 'moon'), guide_type='g_sim_MC', sim_mc_std=0.5, sim_mc_n=100, ep=1e-2, guide_scale=1, guide_schedule='linear_decay', ode_cfg=ODEConfig(t_end=1.0, num_steps=100)), \n",
    "]\n",
    "\n",
    "trajs_g_sim_MC_cfm, w2s_g_sim_MC_cfm = sample_and_compute_w2(guide_cfgs_g_sim_MC_cfm)\n",
    "compute_w2(trajs_g_sim_MC_cfm, guide_cfgs_g_sim_MC_cfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_traj(trajs, cfgs: List[GuideFnConfig], disp_b, skip_ref=False):\n",
    "    blue = cm.get_cmap('coolwarm', 2)(0)\n",
    "    red = cm.get_cmap('coolwarm', 2)(1)\n",
    "    \n",
    "    # visualize, no VF\n",
    "    fig, axs = plt.subplots(3, 8) \n",
    "    r = 6\n",
    "    fig.set_size_inches(8 * r, 3 * r)\n",
    "    \n",
    "    # data1 ref (w/o) ref (g.t.) CFM-MC CFM-GM CFM-CEG OT-CFM-MC OT-CFM-GM OT-CFM-CEG \n",
    "    # data2 ref (w/o) ref (g.t.) CFM-MC CFM-GM CFM-CEG OT-CFM-MC OT-CFM-GM OT-CFM-CEG\n",
    "    # data3 ref (w/o) ref (g.t.) CFM-MC CFM-GM CFM-CEG OT-CFM-MC OT-CFM-GM OT-CFM-CEG\n",
    "    \n",
    "    size_ratio = 0.7\n",
    "    ndata = 3\n",
    "    ncols = 8\n",
    "    nref = 6\n",
    "    nmethods = ncols - nref\n",
    "    \n",
    "    # 1. plot ref distributions\n",
    "    for i in range(ndata):\n",
    "        if skip_ref:\n",
    "            break\n",
    "        cfg = cfgs[i * 6]\n",
    "        x0_dist = get_distribution(cfg.dist_pair[0])\n",
    "        x1_dist = get_distribution(cfg.dist_pair[1])\n",
    "        x0_sampler = x0_dist.sample\n",
    "        x1_sampler = x1_dist.sample\n",
    "        x1 = x1_sampler(1024).to(cfg.ode_cfg.device)\n",
    "        \n",
    "        ax = axs[i, 0]\n",
    "        ax.scatter(x1[:, 0].cpu(), x1[:, 1].cpu(), s=3, color=red)\n",
    "        ax.scatter(x1[:, 0].cpu(), x1[:, 1].cpu(), s=3, color=red)\n",
    "        ax.set_xlim(-cfg.xlim * size_ratio, cfg.xlim * size_ratio)\n",
    "        ax.set_ylim(-cfg.ylim * size_ratio, cfg.ylim * size_ratio)\n",
    "        ax.axis('off')\n",
    "        ax.set_aspect('auto')\n",
    "\n",
    "        \n",
    "        ax = axs[i, 1]\n",
    "        # use regection sampling to sample with weight e^-J in x1\n",
    "        x1 = sample_x1_frompeJ(x1_sampler, x1_dist, cfg.ode_cfg.device, 1024)\n",
    "        ax.scatter(x1[:, 0].cpu(), x1[:, 1].cpu(), s=3, color=red)\n",
    "        ax.set_xlim(-cfg.xlim * size_ratio, cfg.xlim * size_ratio)\n",
    "        ax.set_ylim(-cfg.ylim * size_ratio, cfg.ylim * size_ratio)\n",
    "        ax.set_ylabel(x0_dist.__name__() + '$\\\\rightarrow$' + x1_dist.__name__())\n",
    "        ax.axis('off')\n",
    "        ax.set_aspect('auto')\n",
    "\n",
    "\n",
    "    # 2. plot different methods\n",
    "    for i in range(3):\n",
    "        for j in range(6):\n",
    "            try:\n",
    "                traj = trajs[i * 6 + j]\n",
    "                cfg = cfgs[i * 6 + j]\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            ax = axs[i, j + 2]\n",
    "            # plot the start and end points with endpoint colors in the colormap\n",
    "\n",
    "            idx = torch.randperm(cfg.ode_cfg.batch_size)[:disp_b]\n",
    "            ax.scatter(traj[0, :, 0].cpu(), traj[0, :, 1].cpu(), s=3, color=blue)\n",
    "            ax.scatter(traj[-1, :, 0].cpu(), traj[-1, :, 1].cpu(), s=3, color=red)\n",
    "            # plot the trajectory with a gradient color\n",
    "            colors = torch.linspace(0, 1, cfg.ode_cfg.num_steps).unsqueeze(1).repeat(1, disp_b).flatten().numpy()\n",
    "            ax.scatter(\n",
    "                traj[:, idx, 0].flatten().cpu(), \n",
    "                traj[:, idx, 1].flatten().cpu(), \n",
    "                c=plt.cm.coolwarm(colors), \n",
    "                alpha=0.5, s=0.1, marker='.'\n",
    "            )\n",
    "            # ax.set_title(f'{cfg.dist_pair[0]} to {cfg.dist_pair[1]}')\n",
    "            ax.set_xlim(-cfg.xlim * size_ratio, cfg.xlim * size_ratio)\n",
    "            ax.set_ylim(-cfg.ylim * size_ratio, cfg.ylim * size_ratio)\n",
    "            ax.axis('off')\n",
    "\n",
    "            ax.set_aspect('auto')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose(lst):\n",
    "    return [list(i) for i in zip(*lst)]\n",
    "def flatten(lst):\n",
    "    return [item for sublist in lst for item in sublist]\n",
    "\n",
    "trajs = [trajs_ceg_cfm, trajs_g_sim_MC_cfm, trajs_g_cov_a_cfm, trajs_g_cov_g_cfm, trajs_mc_cfm, trajs_gm_cfm]\n",
    "cfgs = [guide_cfgs_ceg_cfm, guide_cfgs_g_sim_MC_cfm, guide_cfgs_g_cov_a_cfm, guide_cfgs_g_cov_g_cfm, guide_cfgs_mc_cfm, guide_cfgs_gm_cfm]# , guide_cfgs_gm_ot_cfm, guide_cfgs_ceg_ot_cfm])\n",
    "\n",
    "fig = plot_traj(flatten(transpose(trajs)), flatten(transpose(cfgs)), 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('toy.png', dpi=100, bbox_inches='tight',  pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_traj(trajs_g_cov_a_cfm, guide_cfgs_g_cov_a_cfm, 256, skip_ref=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_traj(trajs_g_sim_MC_cfm, guide_cfgs_g_sim_MC_cfm, 256, skip_ref=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "blue = cm.get_cmap('coolwarm', 2)(0)\n",
    "red = cm.get_cmap('coolwarm', 2)(1)\n",
    "\n",
    "ax.scatter([0,], [0], color=red, label='$x_1$')\n",
    "ax.scatter([0,], [0], color=blue, label='$x_0$')\n",
    "ax.legend(ncols=2)\n",
    "fig.savefig('legend.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
